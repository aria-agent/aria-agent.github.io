<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Training Language Agents with Intention-Driven Reward Aggregation">
  <meta name="keywords" content="ARIA, Language Agents, Reinforcement Learning, NLP">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ARIA: Training Language Agents with Intention-Driven Reward Aggregation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link rel="icon" href="static/images/aria_icon.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <style>
    pre {
        max-height: 400px; 
        overflow-x: auto; 
        overflow-y: auto;
        background-color: #f0f0f0; 
        padding: 10px;
        border: 1px solid #ccc; 
        text-align: left;
    }
</style>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://osu-nlp-group.github.io/SeeAct/">
              <b>SeeAct🔥🔥🔥</b>
            </a>
            <a class="navbar-item" href="https://mmmu-benchmark.github.io/">
              <b>MMMU🔥🔥🔥</b>
            </a>
            <a class="navbar-item" href="https://llmbench.ai/agent">
              <b>AgentBench</b>
            </a>
            <a class="navbar-item" href="https://dki-lab.github.io/LLM-Planner/">
              <b>LLM-Planner</b>
            </a>
            <a class="navbar-item" href="https://osu-nlp-group.github.io/Mind2Web/">
              <b>Mind2Web</b>
            </a>
            <a class="navbar-item" href="https://osu-nlp-group.github.io/MagicBrush/">
              <b>MagicBrush</b>
            </a>
          </div>
        </div>
      </div>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title is-bold">
              <img src="static/images/aria_icon.png" style="width:2em;vertical-align: middle" alt="Logo" />
              <span class="mathvista" style="vertical-align: middle">ARIA</span>
            </h1>
            <h2 class="subtitle is-3 publication-subtitle">
              Training Language Agents with Intention-Driven Reward Aggregation
            </h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Ruihan Yang*</a><sup style="color:#6fbf73;">1</sup>,</span>
              <span class="author-block">
                <a href="#">Yikai Zhang*</a><sup style="color:#6fbf73;">1</sup>,</span>
              <span class="author-block">
                <a href="#">Aili Chen</a><sup style="color:#6fbf73;">1</sup>,
              </span>
              <span class="author-block">
                <a href="#">Xintao Wang</a><sup style="color:#6fbf73">1</sup>,
              </span>
              <span class="author-block">
                <a href="#">Siyu Yuan</a><sup style="color:#6fbf73">1</sup>,
              </span>
              <br>
              <span class="author-block">
                <a href="https://jiangjiechen.github.io/">Jiangjie Chen</a><sup style="color:#ed4b82;">2</sup>,
              </span>
              <span class="author-block">
                <a href="#">Deqing Yang</a><sup style="color:#6fbf73;">1†</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=odFW4FoAAAAJ">Yanghua Xiao</a><sup style="color:#6fbf73;">1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup style="color:#6fbf73;">1</sup>Fudan University</span>
              <span class="author-block"><sup style="color:#ed4b82">2</sup>Bytedance Seed</span><br>
              <span class="author-block">* Equal Contribution</span><br>
              <span class="author-block">† Corresponding author</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="static/papers/aria_paper.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="#"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="#"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <p style="font-size:18px">🤗</p>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="content has-text-centered">
        <img src="static/images/aria_overview.png" alt="ARIA Overview" width="100%" />
        <p>Overview of <img src="static/images/aria_icon.png" style="width:1.0em;vertical-align: middle" alt="Logo" />
          ARIA. ARIA first lets agents interact to collect trajectories, then performs semantic projection and aggregates rewards in the intention space, and finally updates the policy using the aggregated rewards.
        </p>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container" style="margin-bottom: 2vh;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Introduction</h2>
          <div class="content has-text-justified">
            <p>
              Large language models (LLMs) have enabled agents to perform complex reasoning and decision-making through free-form language interactions. However, in open-ended language action environments (e.g., negotiation or question-asking games), the action space can be formulated as a joint distribution over tokens, resulting in an extremely large and combinatorial action space. Sampling actions in such a space can lead to extreme reward sparsity, which brings large reward variance, hindering effective reinforcement learning (RL).
            </p>
            <p>
              To address this, we propose ARIA, a method that Aggregates Rewards in Intention space to enable efficient and effective language Agents training. ARIA aims to project natural language actions from the high-dimensional joint token distribution space into a low-dimensional intention space, where semantically similar actions are clustered and assigned shared rewards. This intention-aware reward aggregation reduces reward variance by densifying reward signals, fostering efficient and effective policy optimization.
            </p>
            <p>
              Extensive experiments demonstrate that ARIA not only significantly reduces gradient variance, but also delivers substantial performance gains of average 9.95% across four downstream tasks (e.g., negotiation and text-based games), consistently outperforming strong offline and online RL baselines.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- METHOD SECTION -->
  <section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
      <h1 class="title is-1 mathvista">
        <img src="static/images/aria_icon.png" style="width:1em;vertical-align: middle" alt="Logo" />
        <span class="mathvista" style="vertical-align: middle">ARIA Method</span>
      </h1>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Semantic Projection</h2>
          <div class="content has-text-justified">
            <p>
              We introduce <img src="static/images/aria_icon.png" style="width:1.0em;vertical-align: middle" alt="Logo" />ARIA, which maps token-level actions into a task-specific intention space, enabling reward aggregation across semantically similar actions to stabilize and improve policy learning. The key insight is that LLM agents' actions often reflect underlying intentions, which are far fewer than token sequences.
            </p>
            <p>
              For example, the utterances "I will concede first in order to encourage my opponent to compromise" and "By taking the initiative to compromise, I aim to prompt my counterpart to do the same" convey the same intention of prompting compromise through concession. By grouping such actions under shared intentions, we reduce the action space from V<sup>L</sup> to intention space C, where |C| ≪ |V<sup>L</sup>|.
            </p>
            <div class="content has-text-centered">
              <img src="static/images/semantic_projection.png" alt="Semantic Projection" style="max-width: 80%;" />
              <p>
                Illustration of semantic projection from high-dimensional token space to low-dimensional intention space.
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="columns is-centered m-6">
        <div class="column is-full has-text-centered content">
          <h2 class="title is-3">Reward Aggregation</h2>
          <div class="container is-max-desktop">
            <div class="content has-text-centered">
              <img src="static/images/reward_aggregation.png" alt="Reward Aggregation" style="max-width: 100%;" />
              <p><img src="static/images/aria_icon.png" style="width:1.0em;vertical-align: middle" alt="Logo" />ARIA
                performs hierarchical clustering on sentence embeddings and aggregates rewards within each cluster. This process reduces reward variance while preserving essential discriminative signals.
              </p>
            </div>
          </div>
        </div>
      </div>
    
      <div class="columns is-centered m-6">
        <div class="column is-full has-text-centered content">
          <h2 class="title is-3">Reward-Oriented Granularity Selection</h2>
          <div class="container is-max-desktop">
            <div class="content has-text-centered">
              <img src="static/images/clustering_quality.png" alt="Clustering Quality" style="max-width: 70%;" />
              <p>Reward-oriented granularity selection mechanism that assesses whether further splitting clusters yields meaningful reward change, using SplitScore metric to determine optimal clustering granularity k*.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- RESULTS SECTION -->
  <section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
      <h1 class="title is-1 mathvista">Experimental Results</h1>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="columns is-centered m-6">
        <div class="column is-full has-text-centered content">
          <h2 class="title is-3">Main Results</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/main_results_adversarial.png" alt="Main Results Adversarial" height="50%" />
                <p>Main results on multi-agent games. ARIA achieves significant improvements of 9.67% and 9.83% on Bargaining and Negotiation tasks respectively, consistently outperforming strong offline and online RL baselines.
                </p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/main_results_single.png" alt="Main Results Single" width="80%" />
                <p>
                  Main results on single-agent games. ARIA outperforms all baselines by an average of 9.82% on Twenty Questions and Guess My City tasks, demonstrating its effectiveness across different task types.
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/variance_reduction.png" alt="Variance Reduction" width="80%" />
                <p>Reward variance reduction through aggregation. ARIA significantly reduces reward variance across all four tasks, stabilizing policy learning and enabling more efficient optimization.</p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/online_results.png" alt="Online Results" width="90%" />
                <p>Online ARIA results showing faster convergence and higher returns compared to existing online methods (ArCHer and RAGEN) across iterations.</p>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="columns is-centered m-6">
        <div class="column is-full has-text-centered content">
          <h2 class="title is-3">Analysis and Ablation Study</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/ablation_win_rates.png" alt="Ablation Win Rates" width="60%" />
                <p>Ablation study on win rates showing the contribution of different components of ARIA. Both reward decay and reward aggregation contribute to performance improvements.
                </p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/ablation_loss.png" alt="Ablation Loss" width="60%" />
                <p>Training loss curves under different ablation settings, demonstrating that ARIA accelerates loss reduction and enables faster policy updates through semantic-level reward aggregation.</p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/generalization_results.png" alt="Generalization" width="70%" />
                <p>Generalization results on different models (Qwen2.5-7B and Qwen2.5-1.5B) showing consistent improvements, demonstrating that ARIA is model-agnostic.</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- THEORETICAL ANALYSIS SECTION -->
  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Theoretical Analysis</h2>
          <div class="content has-text-justified">
            <p>
              We provide theoretical analysis showing that intention clustering-based aggregation reduces the variance of gradient descent while maintaining a small bound of bias, thus improving training stability and efficiency.
            </p>
            <p>
              <strong>Variance Reduction:</strong> By replacing original advantages A with cluster-averaged advantages Ã, we remove the intra-cluster variance E[Var(A | C)], lowering the total variance of the policy gradient estimate: Var(Ã) ≤ Var(A).
            </p>
            <p>
              <strong>Bounded Bias:</strong> Through ε-bisimulation analysis, we show that the bias introduced by reward aggregation is bounded: |E[∇θ log πθ(a | h)(A(h, a) − Ã(h, a))]| ≤ O(ε), where actions within each cluster are ε-bisimilar.
            </p>
            <p>
              <strong>Convergence Improvement:</strong> The variance reduction leads to faster convergence with fewer samples: ∥ĝ − g∥₂ = O(√σ/N), where σ is reduced through clustering.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- CASE STUDY SECTION -->
  <section class="section">
    <div class="container">
      <div class="columns is-centered m-6">
        <div class="column is-full has-text-centered content">
          <h2 class="title is-3">Case Studies</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="box m-5">
              <div class="content has-text-left">
                <h4><strong>Twenty Questions Example</strong></h4>
                <pre><code>Actor: Is it a living thing? Oracle: Yes.
Actor: Is it a mammal? Oracle: Yes.
Actor: Is it a human? Oracle: No.
Actor: Is it a carnivore? Oracle: No.
Actor: Is it a cow? Oracle: Yes.</code></pre>
                <p style="text-align: center;">Agent successfully identifies the target object within 5 turns using strategic questioning.</p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-left">
                <h4><strong>Bargaining Example</strong></h4>
                <pre><code>Alice: I'm starting strong, let's start with 60-40 split!
Bob: I propose a more balanced split, considering the inflation 
     effect on your side. What about a 55-45 split?
Alice: I'm willing to compromise, but I want a better share. 
       I propose 70-30 Split!
Bob: Alice, consider that with each round, inflation affects 
     your gains more than mine. This 60-40 split is actually 
     more favorable to you...</code></pre>
                <p style="text-align: center;">Agent demonstrates strategic negotiation skills considering game dynamics and inflation effects.</p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <h4><strong>Clustering Visualization</strong></h4>
                <img src="static/images/clustering_tree.png" alt="Clustering Tree" width="80%" />
                <p>Hierarchical clustering results showing semantic grouping of actions in bargaining scenarios into meaningful intention categories like "Offer", "Decision", "Compromise", etc.</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- BIBTEX SECTION -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-3 has-text-centered">BibTeX</h2>
      <pre><code>@article{yang2024aria,
  title={ARIA: Training Language Agents with Intention-Driven Reward Aggregation},
  author={Yang, Ruihan and Zhang, Yikai and Chen, Aili and Wang, Xintao and Yuan, Siyu and Chen, Jiangjie and Yang, Deqing and Xiao, Yanghua},
  journal={arXiv preprint},
  year={2024}
}</code></pre>
    </div>
  </section>

  <section>
    <div class="section" id="org-banners" style="display:flex">
      <a href="https://www.fudan.edu.cn/en/" target="_blank" rel="external">
        <img class="center-block org-banner" src="static/images/fdu.png" alt="Fudan University">
      </a>
      <a href="https://www.bytedance.com/" target="blank" class="ext-link">
        <img class="center-block org-banner" src="static/images/bytedance.png" alt="Bytedance">
      </a>
    </div>
  </section>

  <footer class="footer">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://mathvista.github.io/">MathVista</a>, licensed under a <a
              rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>